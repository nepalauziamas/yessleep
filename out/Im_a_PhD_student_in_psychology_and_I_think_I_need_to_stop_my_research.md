I've always been intrigued by how groups of human beings make decisions together.

When I was a kid I loved board games, especially when people disagreed on the rules, that was always the most interesting part of playing them. I didn't care about winning, I cared about seeing how we decide who's right. My favorite part of any game has always been when people disagree on how to play, the moment they realize others have different ideas of what the rules are and that they have to figure out how to agree with each other in order to keep playing.

How do we decide? Do we read the rules carefully? Do we vote on them? Does one person give an ultimatum - "If we use your rule I don't want to play anymore"? Do we ask an adult, the final authority? Do we try to convince each other of what the most fun way to play would be? There are so many possible strategies.

I love these questions. As I grew up, I even started noticing patterns. Some personality types prefer to use their intelligence. Calmer people simply let others argue while they read the rules. Sore losers threaten to quit if they don't get their way. Friendly people try to figure out what the most fun way to play is for everyone involved and work towards a compromise. I observe.

Studying psychology was meant to be fun for me, it was supposed to be fascinating. Well. It's definitely still fascinating. I just wish it was fun, too. I didn't think things could take a turn so fast. I really don't know what to do. My supervisor keeps telling me to focus on the science and to not let my emotions cloud my judgement but this whole experiment feels wrong.

Okay, some background. I started my PhD a few months ago, the (provisional) title of my thesis is "Developing a Skinner box model for replicable studies of in-group and out-group formation". It's very wordy, but it's a simple idea: my project is to create an experiment that is easily repeated, that gives us useful information on how humans naturally form groups, i.e. making friends and organizing themselves. Let me give you an example.

You've probably heard of the MBTI? It's a personality test that classifies you into one of 16 different personality types. Maybe we want to know, for example, if a group of 10 people with the ENFP personality type are better at solving problems than a group of 10 people with the INSJ type. Or maybe it would be better to have a mixed group of people with these two personalities?

Right now, we don't really have experiments that can give us answers to questions like these - at least none that are easy to run. My PhD project is to design a social experiment that can answer many different types of questions and test it.

Research isn't done in a vacuum, there are of course experiments that I can and did use as inspiration. My supervisor gave me the keys to the archives on my first day. He told me that, in his experience, new students need to spend a good four months digging through these old research papers, notes and protocols before they're capable of coming up with a good idea that hasn't already been done before.

It was on my second week of exploring the documents in the archives that I noticed the scratches in the hardwood floor in front of one of the large filing cabinets. This cabinet had definitely been moved multiple times. I didn't think much of it at first, but the archives are a terribly tedious place. I should have left well enough alone but I desperately wanted to find something interesting behind this dusty old thing.

There was a safe in the wall. It wasn't a very elaborate safe. It only took me three hours to crack. It was filled with research notes from the CIA's MKULTRA program. For a brief, unfortunately necessary bit of context, MKULTRA is the name the CIA gave to its brainwashing operations.

Yes, brainwashing. The ultimate goal of the program was to be able to manipulate anyone to do anything they want and then have them remember nothing afterwards.

MKULTRA had many subprograms:

\- Operation Midnight Climax tested the effect of secretly giving mind-control drugs to citizens.

\- Subproject 68 was their mind erasing program, the idea was to cure schizophrenic patients by drugging them, covering their eyes and making them listen to recorded words of affirmation (e.g. "You are a good wife and mother and people enjoy your company") for 20 hours a day every day for weeks.

\- QK-HILLTOP investigated Chinese torture techniques developed under Mao.

All of these experiments, unjustifiable, unethical, not even useful. All of them were sadistic torture programs masquerading as "psychology". I haven't been able to sleep very much but this... morbid curiosity has kept me reading. What if there's something useful in there? What if they did learn something about the human mind?

After finding nothing but dread and vivid descriptions of vivisections (don't look that up) and systematic depersonalization methods, I almost convinced myself to stop reading, but one of the experiments caught my eye.

HWRESET was just as barbaric as the others, but it had potential. I could strip away all of its horror and make it pure and scientific. The original experiment's stated goal was to “Accelerate development of the ultimate weapon".

The experiment was complex, but the core idea was simple. The CIA used their extensive - and secret - budget to build a small town in the middle of Nowhere, Classified. They populated it by giving illegal immigrants the choice to be extradited or to sign away their rights and move into a nice house. Once everyone had moved in, they built a massive wall around the small town, guarding it using methods they later passed on to the Germans in Berlin. 145 adult men, 152 adult women and 16 children were trapped without warning and without sufficient food, water or medical supplies to last a full winter.

The HWRESET program's Pythagoras Project began at 5:00 AM that morning when spotlights mounted on the surrounding walls flooded the town with light and sirens filled its population of 313 with fears of imminent nuclear annihilation.

Nuclear annihilation would have been merciful.

Armed and masked agents rounded everyone up and made each person walk into a room with three doors. Each door was a different color: red, green, and blue. No instructions were given, this was the self-classification stage. Each participant has actively chosen their path. Well, not every participant.

Those who stayed in the selection room and never chose a door were eliminated.

Each of the color rooms had a small table at the center, with a large button on it. Sometimes, the button would light up, and when someone pushed it, the light went off. There were no other features to the room.

The participants were then each told the same story. The story they were told is an information hazard. An information hazard is information that is intrinsically dangerous. For example, if I gave you a detailed explanation of how to build a nuclear bomb, that would be an information hazard. If you looked into your next door neighbor's car and found a bloody knife and rope, that would also be one. Knowing things can be dangerous and alter the trajectory of your life. I shouldn't tell you what they were told. >!Those who do not push the button will be eliminated.!<

So each room was given the same information hazard. Most of the people in each room believed it - you tend to believe people pointing guns at you - but some were naturally skeptical. The doors were shut and locked from the outside, it was clear no one was allowed to leave. In every room, there were participants who tried to convince the others never to push the button. They were subject to harsh treatment and dehumanization, treated as outcasts and were the last to be given food, if any was left. >!If you push the button, there is a small chance a beast will be unleashed and cause great havoc.!<

Some thought the button should be pushed at regular intervals. Others believed that the only way to leave was for each person to push the button once. Some thought that every time the button is pushed, a timer is reset, preventing them from being freed. The only way to leave is to refuse to push the button. >!If you push the button a lot to prove your worth, you will be granted power.!<

The CIA wanted to study how information hazards affect people to develop and weaponize information itself. Their vision of information warfare was to be taken literally. They kept running and fine-tuning this experiment, over and over again with more and more test participants. They weren't only interested in developing the information hazards, but also of identifying the people most vulnerable to them, and those who are the most able to exploit others under these circumstances, and how they did it. Everything was monitored, observed, documented. All of the violence, torture, systematic dehumanization. The rise to power of psychopathic individuals in a resource-scarce social experiment. They scientifically developed hell on earth.

They didn't see the potential that I see in their own experiment. If we remove the information hazards it becomes a pure investigation into human social decision-making. You and 99 others are imprisoned in a room. There is one button at the center of this room. How do you all decide what the rules are? How do you come to an agreement? What can we learn when we observe humans self-organize into micro-societies and plan their decision making around a button that does absolutely nothing?

The potential of this experiment is endless. What if we change the experiment slightly, make it so that pushing the button gives you food? What if we make it so that you're eliminated if you push the button? I had so many questions this could answer. Is self-organizing into hierarchies an innate human quality?

But it never worked. I thought I could recreate the experiment without the violence. Without the information hazard. People simply didn't care about a button without *motivation*. Nothing happened, the experiments were all failures.

I thought it would be harmless to introduce a little information hazard. I told them to think about it like an escape room. I told them that the story I was about to tell them was not real. I even picked a story that was incredibly implausible, easy to dismiss with any level of scrutiny. I thought it could be safe if everyone had informed consent. People still became mean, insulting each other, threatening violence, starting fights.

Over these past few months, the escalating tensions in the experiment we're running made me increasingly concerned for the safety of participants. I thought the only way to guarantee everyone's safety would be if it was a purely voluntary, online-only experiment. So that people can't physically harm each other. This is how I came into contact with Alex, a computer science graduate who I worked with to develop an online version of this experiment.

Alex was never very communicative, but used to respond to emails in a timely way. I found out last Thursday that all of the code to automatically run this experiment was published online, on github last thursday. This is despite all of our warnings that it could trigger an ethics investigation if done without proper authorization from the ethics board. I think Alex fell prey to the information hazard. I thought nothing of it at the time, but I understand now that this dangerous thought can compromise anyone.

How did I overlook so much? I was so focused on the in-person experiment. I thought I could interrupt it to give everyone some reassurance and reset tensions. I really believe the experiment would be safe if I made it clear in person to everyone that no one is physically harmed when eliminated in the weekly purge. I didn't think anyone could get hurt if we gave everyone the option to leave at any time simply by saying "I would like to leave". I was convinced no harm would befall anyone if we monitored the camera feeds and intervened if anything started to feel dangerous. I thought I could conduct this safely. I should have chosen a different information hazard, the one I chose is too dangerous and it's already started spreading. I've unleashed something terrible.

My supervisor keeps telling me to focus on the science and not to let my emotions cloud my judgement. I wish I could still decide to stop my thesis.

I'm writing this on the 17th of July 2022. Earlier today, at 4:30 PM, I had a heated discussion with my supervisor over the progression of our... my, experiment, and the safety protocols put in place. The participants in the blue room have disabled the cameras an hour ago. The red room's cameras went down twenty minutes later. The green room five minutes after that. I can't stop hearing the screams that broadcast before the cameras were disabled. My supervisor left a dozen messages on my phone. I've shut my phone off with the microwave. I've signed out of all my e-mails. I feel unsafe here. I need to run away. I don't want to know what they've done to each other. I know what they did to each other in the '50s.

I didn't think it would be so dangerous and spread so fast. I don't know how many rooms have been created using Alex's code. I only know it was downloaded a hundred and twelve times before I broke into the server room and deleted all local traces of it an hour ago. The IP addresses it was downloaded by come from all over the world. The US, China, Russia, North Korea, India, Brazil, the UK, France, South Africa... Everywhere. I write this as a warning. This experiment cannot be made safe. The information hazard I used will be the end of us all if we don't stop it. Humans will self-organize and self-radicalize. Please stop creating rooms. Please stop joining rooms. Please do not attempt to find this information hazard. Please stop spreading it. The fate of humanity depends on it.

Please stop pushing the button. S'il vous plaît, arrêtez d'appuyer sur le bouton. ボタンを押すのをやめてください .  П ожалуйста, перестань нажимать на кнопку.  請停止按下按鈕 . Por favor deja de presionar el botón. .من فضلك توقفوا عن الضغط على الزر  Hou asseblief op om die knoppie te druk.

&#x200B;

>!https://discord.gg/E22ZZreed6!<